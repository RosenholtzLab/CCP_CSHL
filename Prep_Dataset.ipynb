{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343008b0-86b4-4eaa-a1a1-98a521adfa74",
   "metadata": {},
   "source": [
    "# Prep Dataset for of Images for CSHL Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75193676-d566-43a2-8bb1-aa35e09af8b3",
   "metadata": {},
   "source": [
    "## COCO-Search 18\n",
    "[COCO Search 18](https://saliency.tuebingen.ai/datasets/COCO-Search18/)  \n",
    "\n",
    "\n",
    "This block demos acessing the JSON file of COCO Search 18. You can access other keys of the train and val (other than 'name') to get the fixation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad3faca-1ea8-4c5c-8f54-6f4432b7de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example JSON Entry:\n",
      "{'name': '000000478726.jpg', 'subject': 2, 'task': 'bottle', 'condition': 'present', 'bbox': [1063, 68, 95, 334], 'X': [848.2, 799.2, 731.1, 1114.4, 1121.5], 'Y': [517.2, 476.2, 383.4, 271.1, 205.9], 'T': [73, 193, 95, 635, 592], 'length': 5, 'correct': 1, 'RT': 1159, 'split': 'train'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the JSON file\n",
    "with open('./coco_search18/coco_search18_fixations_TP_train_split1.json', 'r') as file:\n",
    "    train = json.load(file)\n",
    "# Open the JSON file\n",
    "with open('./coco_search18/coco_search18_fixations_TP_validation_split1.json', 'r') as file:\n",
    "    val = json.load(file)\n",
    "    \n",
    "train_split = []\n",
    "# Now 'train' contains the JSON data as a Python dictionary\n",
    "for d in train:\n",
    "    train_split.append(d['name'])\n",
    "\n",
    "val_split = []\n",
    "# Now 'train' contains the JSON data as a Python dictionary\n",
    "for d in val:\n",
    "    val_split.append(d['name'])\n",
    "\n",
    "print('Example JSON Entry:')\n",
    "print(train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6b5ec-77e6-4074-8879-708b57792609",
   "metadata": {},
   "source": [
    "There are ducplicate names in our lists because there are mulitple entries for individual images. Remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e79948-d447-422f-bf48-46404f6ee7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Before:\n",
      "Train:  21622\n",
      "Val:  3258\n",
      "Size After:\n",
      "Train:  1934\n",
      "Val:  315\n"
     ]
    }
   ],
   "source": [
    "print('Size Before:')\n",
    "print('Train: ',len(train_split))\n",
    "print('Val: ',len(val_split))\n",
    "\n",
    "train_split = list(set(train_split))\n",
    "val_split = list(set(val_split))\n",
    "\n",
    "print('Size After:')\n",
    "print('Train: ',len(train_split))\n",
    "print('Val: ',len(val_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1308578-80ae-4f35-8efa-b30a5cdd6591",
   "metadata": {},
   "source": [
    "## COCO-Periph\n",
    "\n",
    "COCO-Periph has a subset of images that are complete with all 4 eccentricities rendered.\n",
    "\n",
    "I Used this script to pick 100 of the training images that have all 4 eccentricities of coco-periph. You can chose more (there are 990 in total), the full list is in ccp_search_subset_train.csv\n",
    "\n",
    "You can copy the rest of them to your local machine, as well as the test and validation by downloading the full COCO-Periph dataset from [https://data.csail.mit.edu/coco_periph/](https://data.csail.mit.edu/coco_periph/) and changing the filepath. You may also need to change the fname_80,160,240,320 as well to match the public dataset formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7632ab1-c23f-4647-9cb9-79a5eec22901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_in_cocop(imgnum,filepath='./COCO_Periph'):\n",
    "    '''\n",
    "    Check if img has complete cocop dataset\n",
    "\n",
    "    Parameters:\n",
    "        imgnum (str): the MS COCO Image number desired\n",
    "        filepath (str): path to the COCO Periph Directory\n",
    "    Returns:\n",
    "        imglist_subset (list of strings): \n",
    "    '''\n",
    "    fname_80 = os.path.join(filepath,'ecc_80',f'{imgnum.zfill(12)}.jpg')\n",
    "    fname_160 = os.path.join(filepath,'ecc_160',f'{imgnum.zfill(12)}.jpg')\n",
    "    fname_240 = os.path.join(filepath,'ecc_240',f'{imgnum.zfill(12)}.jpg')\n",
    "    fname_320 = os.path.join(filepath,'ecc_320',f'{imgnum.zfill(12)}.jpg')\n",
    "    \n",
    "    \n",
    "    if all([os.path.isfile(fname_80),\n",
    "            os.path.isfile(fname_160),\n",
    "            os.path.isfile(fname_240),\n",
    "            os.path.isfile(fname_320)]):\n",
    "\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "check_in_cocop('9',filepath='../coco_periph_data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7b29b1-b40e-47ea-bd52-867ed2d4b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n"
     ]
    }
   ],
   "source": [
    "complete_subset_train = []\n",
    "for img in train_split:\n",
    "    if check_in_cocop(img.replace('.jpg',''),filepath='../coco_periph_data/train/'):\n",
    "        complete_subset_train.append(img)\n",
    "        \n",
    "print(len(complete_subset_train))\n",
    "\n",
    "import csv\n",
    "# Open the file in write mode\n",
    "with open('./ccp_search_subset_train.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write each string as a separate row in the CSV file\n",
    "    for string in complete_subset_train:\n",
    "        writer.writerow([string])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186377de-c4f4-4aee-8146-87910a07a1e8",
   "metadata": {},
   "source": [
    "## Select a subset of these\n",
    "I used this script to pick a randomly chosen subset of 100 and copy them from our internal server to create the ccp_search18_train_subset folder used for the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aaf7dbe-1ab2-47a5-96cc-a36b073e1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand_subset = random.sample(complete_subset_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae53a8cb-e091-4fa7-950b-b293455d9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "eccs = [5,10,15,20]\n",
    "ppd=16\n",
    "\n",
    "for img in rand_subset:\n",
    "\n",
    "    #zero ecc first (original MS coco image)\n",
    "    src = f'/home/gridsan/groups/datasets/coco/train2017/{img}'\n",
    "    dst = f'ccp_search18_train_subset/ecc_0/{img}'\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "    #loop through eccentricities\n",
    "    for ecc in eccs:\n",
    "        src = f'/home/gridsan/groups/RosenholtzLab/coco_periph_data/train/ecc_{ecc*ppd}/{img}'\n",
    "        dst = f'ccp_search18_train_subset/ecc_{ecc}/{img}'\n",
    "        shutil.copyfile(src, dst)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
